{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a04567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10556855</td>\n",
       "      <td>MINORITY ORGAN &amp; TISSUE TRANSPLANT &amp; EDUCATION...</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10558440</td>\n",
       "      <td>FRIENDS OF ARTS COUNCIL OF GREATER DENHAM SPRI...</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10566033</td>\n",
       "      <td>ISRAEL EMERGENCY ALLIANCE</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10M-50M</td>\n",
       "      <td>N</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10570430</td>\n",
       "      <td>ARAMCO BRATS INC</td>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10571689</td>\n",
       "      <td>INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                               NAME  \\\n",
       "0  10520599                       BLUE KNIGHTS MOTORCYCLE CLUB   \n",
       "1  10531628             AMERICAN CHESAPEAKE CLUB CHARITABLE TR   \n",
       "2  10547893                 ST CLOUD PROFESSIONAL FIREFIGHTERS   \n",
       "3  10553066                     SOUTHSIDE ATHLETIC ASSOCIATION   \n",
       "4  10556103           GENETIC RESEARCH INSTITUTE OF THE DESERT   \n",
       "5  10556855  MINORITY ORGAN & TISSUE TRANSPLANT & EDUCATION...   \n",
       "6  10558440  FRIENDS OF ARTS COUNCIL OF GREATER DENHAM SPRI...   \n",
       "7  10566033                          ISRAEL EMERGENCY ALLIANCE   \n",
       "8  10570430                                   ARAMCO BRATS INC   \n",
       "9  10571689         INTERNATIONAL ASSOCIATION OF FIRE FIGHTERS   \n",
       "\n",
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "5               T3       Independent          C1200  Preservation   \n",
       "6               T3       Independent          C1000  Preservation   \n",
       "7               T3       Independent          C2000  Preservation   \n",
       "8               T7       Independent          C1000    ProductDev   \n",
       "9               T5  CompanySponsored          C3000    ProductDev   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "5         Trust       1              0                      N     5000   \n",
       "6         Trust       1  100000-499999                      N    31452   \n",
       "7         Trust       1        10M-50M                      N  7508025   \n",
       "8         Trust       1         1-9999                      N    94389   \n",
       "9   Association       1              0                      N     5000   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  \n",
       "5              1  \n",
       "6              1  \n",
       "7              1  \n",
       "8              1  \n",
       "9              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cc60e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "10000-24999        543\n",
       "10M-50M            240\n",
       "5M-10M             185\n",
       "50M+               139\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at INCOME_AMT value counts for binning\n",
    "income_counts = application_df.INCOME_AMT.value_counts()\n",
    "income_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9be6485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "10000-24999        543\n",
       "10M-50M            240\n",
       "5M-10M             185\n",
       "50M+               139\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = application_df['INCOME_AMT'].value_counts()\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf256a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "Other              564\n",
       "10000-24999        543\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 100?\n",
    "replace_class = list(test2[test2 < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.INCOME_AMT = application_df.INCOME_AMT.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.INCOME_AMT.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2bd3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    18261\n",
       "0    16038\n",
       "Name: IS_SUCCESSFUL, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = application_df['IS_SUCCESSFUL']\n",
    "test1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aa00195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>N</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>N</td>\n",
       "      <td>69656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>165593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2700</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>N</td>\n",
       "      <td>5301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0               T10       Independent          C1000    ProductDev   \n",
       "1                T3       Independent          C2000  Preservation   \n",
       "2                T5  CompanySponsored          C3000    ProductDev   \n",
       "3                T3  CompanySponsored          C2000  Preservation   \n",
       "4                T3       Independent          C1000     Heathcare   \n",
       "5                T3       Independent          C1200  Preservation   \n",
       "6                T3       Independent          C1000  Preservation   \n",
       "7                T3       Independent          C2000  Preservation   \n",
       "8                T7       Independent          C1000    ProductDev   \n",
       "9                T5  CompanySponsored          C3000    ProductDev   \n",
       "10               T3       Independent          C1200  Preservation   \n",
       "11               T3       Independent          C2000  Preservation   \n",
       "12               T3  CompanySponsored          C1200  Preservation   \n",
       "13               T3       Independent          C2700  Preservation   \n",
       "14               T3       Independent          C1000  Preservation   \n",
       "\n",
       "    ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0    Association       1              0                      N     5000   \n",
       "1   Co-operative       1         1-9999                      N   108590   \n",
       "2    Association       1              0                      N     5000   \n",
       "3          Trust       1    10000-24999                      N     6692   \n",
       "4          Trust       1  100000-499999                      N   142590   \n",
       "5          Trust       1              0                      N     5000   \n",
       "6          Trust       1  100000-499999                      N    31452   \n",
       "7          Trust       1          Other                      N  7508025   \n",
       "8          Trust       1         1-9999                      N    94389   \n",
       "9    Association       1              0                      N     5000   \n",
       "10         Trust       1    25000-99999                      N    69656   \n",
       "11         Trust       1  100000-499999                      N   165593   \n",
       "12   Association       1              0                      N     5000   \n",
       "13         Trust       1    25000-99999                      N     5301   \n",
       "14         Trust       1              0                      N     5000   \n",
       "\n",
       "    IS_SUCCESSFUL  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               1  \n",
       "5               1  \n",
       "6               1  \n",
       "7               1  \n",
       "8               1  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "12              1  \n",
       "13              1  \n",
       "14              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df.drop(columns=['EIN', 'NAME'], inplace=True)\n",
    "application_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4773b3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   7\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86f6d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1800 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "amount_outliers = application_df[['ASK_AMT']]\n",
    "amount_outliers.boxplot(column=['ASK_AMT'], figsize = [24,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbebafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "Other              564\n",
       "10000-24999        543\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask/income amount--thats a lot of 5000 asks\n",
    "ask_counts = application_df.ASK_AMT.value_counts()\n",
    "ask_counts\n",
    "inc_counts = application_df.INCOME_AMT.value_counts()\n",
    "inc_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb99e141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Look at APPLICATION_TYPE value counts for binning\n",
    "app_counts = application_df.APPLICATION_TYPE.value_counts()\n",
    "app_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08720626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "Other     2266\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 50?  should this be 100?\n",
    "replace_application = list(app_counts[app_counts < 800].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cd05202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C2170      1\n",
       "C2700    104\n",
       "C1237      9\n",
       "C1400     34\n",
       "C8000     20\n",
       "C1820      1\n",
       "C1300     58\n",
       "C7120     18\n",
       "C1246      2\n",
       "C1245      1\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_counts = application_df.CLASSIFICATION.value_counts()\n",
    "class_counts.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21dd2008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Other     1484\n",
       "C7000      777\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 100?\n",
    "replace_class = list(class_counts[class_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65944b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE          6\n",
       "AFFILIATION               6\n",
       "CLASSIFICATION            7\n",
       "USE_CASE                  5\n",
       "ORGANIZATION              4\n",
       "INCOME_AMT                7\n",
       "SPECIAL_CONSIDERATIONS    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate our categorical variable lists\n",
    "app_cats = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\n",
    "application_df[app_cats].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b4a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e140563/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_Other</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                     1.0                   0.0                  0.0   \n",
       "1                     0.0                   0.0                  1.0   \n",
       "2                     0.0                   0.0                  0.0   \n",
       "3                     0.0                   0.0                  1.0   \n",
       "4                     0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  1.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           1.0                        0.0   \n",
       "3                           1.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  ...  ORGANIZATION_Trust  \\\n",
       "0                      1.0                   0.0  ...                 0.0   \n",
       "1                      1.0                   0.0  ...                 0.0   \n",
       "2                      0.0                   0.0  ...                 0.0   \n",
       "3                      0.0                   0.0  ...                 1.0   \n",
       "4                      1.0                   0.0  ...                 1.0   \n",
       "\n",
       "   INCOME_AMT_0  INCOME_AMT_1-9999  INCOME_AMT_10000-24999  \\\n",
       "0           1.0                0.0                     0.0   \n",
       "1           0.0                1.0                     0.0   \n",
       "2           1.0                0.0                     0.0   \n",
       "3           0.0                0.0                     1.0   \n",
       "4           0.0                0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                       0.0               0.0                     0.0   \n",
       "1                       0.0               0.0                     0.0   \n",
       "2                       0.0               0.0                     0.0   \n",
       "3                       0.0               0.0                     0.0   \n",
       "4                       1.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_Other  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0               0.0                       1.0                       0.0  \n",
       "1               0.0                       1.0                       0.0  \n",
       "2               0.0                       1.0                       0.0  \n",
       "3               0.0                       1.0                       0.0  \n",
       "4               0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[app_cats]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(app_cats)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29240bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/e140563/opt/anaconda3/envs/mlenv/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_Other</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     1.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  AFFILIATION_CompanySponsored  \\\n",
       "0                  0.0                  0.0                           0.0   \n",
       "1                  0.0                  0.0                           0.0   \n",
       "2                  1.0                  0.0                           1.0   \n",
       "3                  0.0                  0.0                           1.0   \n",
       "4                  0.0                  0.0                           0.0   \n",
       "\n",
       "   ...  ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0  ...                 0.0           1.0                0.0   \n",
       "1  ...                 0.0           0.0                1.0   \n",
       "2  ...                 0.0           1.0                0.0   \n",
       "3  ...                 1.0           0.0                0.0   \n",
       "4  ...                 1.0           0.0                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_1M-5M  \\\n",
       "0                     0.0                       0.0               0.0   \n",
       "1                     0.0                       0.0               0.0   \n",
       "2                     0.0                       0.0               0.0   \n",
       "3                     1.0                       0.0               0.0   \n",
       "4                     0.0                       1.0               0.0   \n",
       "\n",
       "   INCOME_AMT_25000-99999  INCOME_AMT_Other  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                     0.0               0.0                       1.0   \n",
       "1                     0.0               0.0                       1.0   \n",
       "2                     0.0               0.0                       1.0   \n",
       "3                     0.0               0.0                       1.0   \n",
       "4                     0.0               0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df, left_index=True, right_index = True)\n",
    "application_df.drop(app_cats,1, inplace=True)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "971acab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df.IS_SUCCESSFUL.values\n",
    "X = application_df.drop(columns=['IS_SUCCESSFUL'])\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3106ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14ee5bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                294       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,129\n",
      "Trainable params: 2,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 12:39:17.825488: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Best checkpoint .7458\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 30\n",
    "hidden_nodes_layer2 = 20\n",
    "hidden_nodes_layer3 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9a4d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0560e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 12:39:17.971402: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "804/804 [==============================] - 2s 1ms/step - loss: 0.6133 - accuracy: 0.6790\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5573 - accuracy: 0.7294\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5563 - accuracy: 0.7287\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5540 - accuracy: 0.7292\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5518 - accuracy: 0.7292\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5495 - accuracy: 0.7353\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5455 - accuracy: 0.7339\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7361\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5500 - accuracy: 0.7306\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5411 - accuracy: 0.7375\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7362\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5427 - accuracy: 0.73900s - loss: 0.5398 - \n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7383\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7361: 0s - loss: 0.5454 - accuracy: 0.73 - ETA: 0s - loss: 0.5454 - accuracy\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 998us/step - loss: 0.5355 - accuracy: 0.7422\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7352: 0s - loss: 0.5\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7329\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7365: 0s - loss: 0.5430 - accuracy\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5431 - accuracy: 0.7358\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5492 - accuracy: 0.7335\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5429 - accuracy: 0.7372\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5416 - accuracy: 0.7379\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7399\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 955us/step - loss: 0.5434 - accuracy: 0.7371\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5420 - accuracy: 0.7381\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7413\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7353: 0s - loss: 0.547\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 995us/step - loss: 0.5393 - accuracy: 0.7398\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5440 - accuracy: 0.73650s - loss: 0.5446 - \n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7408: 0s - loss: 0.5335 - accura - ETA: 0s - loss: 0.5365 - accu\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5392 - accuracy: 0.7374\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5390 - accuracy: 0.73950s - loss: 0.5389 - accuracy: 0.73\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7454\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 1000us/step - loss: 0.5426 - accuracy: 0.7378s - loss: 0.542\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7410\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7458\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7401\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7368\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5393 - accuracy: 0.7393\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5396 - accuracy: 0.7416\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5380 - accuracy: 0.7400\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7427: 0s - loss: 0.5318 - \n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7370\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7395: 0s - loss: 0.5390 -  - ETA: 0s - loss: 0.5378 - accu\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7380\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7363: 0s - loss: 0.5464 - accu - ETA: 0s - loss: 0.5445 - accuracy\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7384\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7393\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7405: 0s - loss: 0.5\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7406: 0s - loss: 0.5408 - accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "mc = keras.callbacks.ModelCheckpoint('weights/weights1{epoch:08d}.hdf5', \n",
    "                                     save_weights_only=True, period=5)\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "377c370a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5586 - accuracy: 0.7268\n",
      "Loss: 0.5586140155792236, Accuracy: 0.7267638444900513\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81062fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                1200      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 14)                294       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,129\n",
      "Trainable params: 2,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#trying tanh activation function Best checkpoint .7455\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 30\n",
    "hidden_nodes_layer2 = 20\n",
    "hidden_nodes_layer3 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32cf3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58ee4ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.6000 - accuracy: 0.6856\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5646 - accuracy: 0.7247\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5565 - accuracy: 0.7322\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5557 - accuracy: 0.7303\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7298\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5503 - accuracy: 0.7323\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5515 - accuracy: 0.7301\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5479 - accuracy: 0.7352: 0s - loss: 0.5477 - accuracy: 0.\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5513 - accuracy: 0.7313\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7377: 0s - loss: 0.541 - ETA: 0s - loss: 0.5455 - accuracy: \n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7337\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7365\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7321\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7353\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7384: 0s - loss: 0.537\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7363: 0s - loss: 0.542\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7379: 0s - loss: 0\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5446 - accuracy: 0.7350: 0s - loss: 0.5444 \n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7351\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7346\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7382: 0s - loss: 0.5423 - accuracy: \n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7340\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.7397\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7356\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7392: 0s - loss: 0.5403 - \n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7420\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7385\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5426 - accuracy: 0.7350\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7377: 0s - loss: 0.5409 - accura\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5469 - accuracy: 0.7337\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7389\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7388\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7362\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7408\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7370\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7376\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7387\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7348\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7381: 0s - loss: 0.5423 - accura - ETA: 0s - loss: 0.5420 - accuracy: \n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7407: 0s - loss: 0.5409 - accuracy: 0.\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7422\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7386\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7415\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7398\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5437 - accuracy: 0.7355\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7389\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7355\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5317 - accuracy: 0.7455\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7385\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7341\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "mc = keras.callbacks.ModelCheckpoint('weights/weights2{epoch:08d}.hdf5', \n",
    "                                     save_weights_only=True, period=5)\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cf26fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5580 - accuracy: 0.7241\n",
      "Loss: 0.5580378770828247, Accuracy: 0.7240816354751587\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea11e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 30)                1200      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 14)                294       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,129\n",
      "Trainable params: 2,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#trying tanh activation function --Best checkpoint is .7420\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 30\n",
    "hidden_nodes_layer2 = 20\n",
    "hidden_nodes_layer3 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3639eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "496cbd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "804/804 [==============================] - 2s 2ms/step - loss: 0.6107 - accuracy: 0.6821\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5560 - accuracy: 0.7333\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5575 - accuracy: 0.7315\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5570 - accuracy: 0.7265\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5508 - accuracy: 0.7336: 0s - loss: 0.5507 - ac\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5528 - accuracy: 0.7292: 0s - loss: 0.5532 - accuracy\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5473 - accuracy: 0.7395\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5478 - accuracy: 0.7378\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7343\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5499 - accuracy: 0.7333\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5459 - accuracy: 0.7345\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5458 - accuracy: 0.7343\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7339\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5448 - accuracy: 0.7396\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7382\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7336\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7365\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7346: 0s - loss: 0.5436 - accuracy\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7397\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 998us/step - loss: 0.5475 - accuracy: 0.7315\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7369\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7335: 0s - loss: 0.5\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7389\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7379: 0s - loss: 0.5432 - accuracy\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5470 - accuracy: 0.7347: 0s - loss: 0.5476 - accuracy\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7357\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5444 - accuracy: 0.7350\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7405: 0s - los\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7408: 0s - loss: 0.5363 - accuracy: 0. - ETA: 0s - loss: 0.5371 - accuracy\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7394\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7362\n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7405\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7350\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7383: 0s - loss: 0.5385 \n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5415 - accuracy: 0.7382\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7404\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7404: 0s - loss: 0.5393 - accuracy\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7411: 0s - loss: 0.5372 \n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7402\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5422 - accuracy: 0.7365\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7376\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7374: 0s - los\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7420\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7369: 0s - loss: 0.5416 - accuracy\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7362\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7393\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7350: 0s - loss: 0.5\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7365\n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7366: 0s - los\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7384\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "mc = keras.callbacks.ModelCheckpoint('weights/weights4{epoch:08d}.hdf5', \n",
    "                                     save_weights_only=True, period=5)\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48953cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5583 - accuracy: 0.7231\n",
      "Loss: 0.5582756996154785, Accuracy: 0.7231487035751343\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c6022bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 30)                1200      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 14)                294       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 2,129\n",
      "Trainable params: 2,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Best checkpoint .7443\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 30\n",
    "hidden_nodes_layer2 = 20\n",
    "hidden_nodes_layer3 = 14\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "#Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"tanh\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3db4c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fe87fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5989 - accuracy: 0.6922\n",
      "Epoch 2/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5546 - accuracy: 0.7323\n",
      "Epoch 3/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7337: 0s - loss: 0.5513 - accuracy:  - ETA: 0s - loss: 0.5520 - accura\n",
      "Epoch 4/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5518 - accuracy: 0.7347\n",
      "Epoch 5/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5509 - accuracy: 0.7329\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5509 - accuracy: 0.7341: 0s - loss: 0\n",
      "Epoch 7/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5540 - accuracy: 0.7308: 0s - los\n",
      "Epoch 8/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5477 - accuracy: 0.7353: 0s - loss: 0.5477 - accuracy: 0.73\n",
      "Epoch 9/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5509 - accuracy: 0.7311\n",
      "Epoch 10/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5520 - accuracy: 0.7323\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5513 - accuracy: 0.7318\n",
      "Epoch 12/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7390\n",
      "Epoch 13/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7373\n",
      "Epoch 14/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7343\n",
      "Epoch 15/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7369\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7363\n",
      "Epoch 17/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7330\n",
      "Epoch 18/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7430\n",
      "Epoch 19/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7381: 0s - loss: 0.5429 - accuracy: 0.73\n",
      "Epoch 20/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7398\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7373\n",
      "Epoch 22/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7336\n",
      "Epoch 23/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7344\n",
      "Epoch 24/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7443\n",
      "Epoch 25/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7385: 0s - loss: 0.5\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7417\n",
      "Epoch 27/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7411\n",
      "Epoch 28/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5483 - accuracy: 0.7334: 0s - loss: 0.553\n",
      "Epoch 29/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7391\n",
      "Epoch 30/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7368: 0s - loss: 0.5387 - \n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5428 - accuracy: 0.7371: 0s - loss: 0.5466 -  - ETA: 0s - loss: 0.5440 - \n",
      "Epoch 32/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5493 - accuracy: 0.7309: 0s - loss: 0.552\n",
      "Epoch 33/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7410\n",
      "Epoch 34/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7389\n",
      "Epoch 35/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7335\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7370\n",
      "Epoch 37/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7399\n",
      "Epoch 38/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7395\n",
      "Epoch 39/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7408\n",
      "Epoch 40/50\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.7344\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7378\n",
      "Epoch 42/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7433\n",
      "Epoch 43/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7429\n",
      "Epoch 44/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7413\n",
      "Epoch 45/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7407\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7415\n",
      "Epoch 47/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7400: 0s - loss: 0.5348 - accura\n",
      "Epoch 48/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7413: 0s - loss: 0.5330  - ETA: 0s - loss: 0.5368 - accuracy: \n",
      "Epoch 49/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7395: 0s - loss: 0\n",
      "Epoch 50/50\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7404: 0s - loss: 0.535\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "mc = keras.callbacks.ModelCheckpoint('weights/weights4{epoch:08d}.hdf5', \n",
    "                                     save_weights_only=True, period=5)\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
